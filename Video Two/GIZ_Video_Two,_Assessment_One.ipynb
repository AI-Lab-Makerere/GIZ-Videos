{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GIZ_Video_Two,_Assessment_One.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUR6-QsKPaeO"
      },
      "source": [
        "# How to access open Earth observation training data\n",
        "### **Assessment One**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JjjRPPxNBVq"
      },
      "source": [
        "#1. Authentication and API properties\n",
        "\n",
        "Enter your Radiant MLHub access token and API properties"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9tlI_ySMyPc"
      },
      "source": [
        "# only the requests module is required to access the API at this stage\n",
        "import requests\n",
        "\n",
        "API_BASE = 'http://api.radiant.earth/mlhub/v1'\n",
        "\n",
        "# copy your access token from dashboard.mlhub.earth and paste it in the following\n",
        "ACCESS_TOKEN = 'PASTE THE TOKEN FROM YOUR RADIANT MLHUB DASHBOARD HERE'\n",
        "\n",
        "# these headers will be used in each request\n",
        "headers = {\n",
        "    'Authorization': f'Bearer {ACCESS_TOKEN}',\n",
        "    'Accept':'application/json'\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhaU8YkWF4ty"
      },
      "source": [
        "#2. Get List of all collections\n",
        "\n",
        "To see what training data is available, you will want to see the collections available through the API\n",
        "\n",
        "A collection represents the top-most data level. Typically this means the data comes from the same source for the same geography. It might include different years or sub-geographies.\n",
        "\n",
        "To see the list, simply run the following cell. The returned list shows the collection id values, collection license, and data source citation (if available)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlYHJwkTGlkn"
      },
      "source": [
        "# get list of all collections\n",
        "r = requests.get(f'{API_BASE}/collections', headers=headers)\n",
        "h = r.json()\n",
        "collections = h['collections']\n",
        "\n",
        "# print the list of collections \n",
        "for c in collections:\n",
        "    print(f'ID:       {c[\"id\"]}\\nLicense:  {c.get(\"license\", \"N/A\")}\\nCitation: {c.get(\"sci:citation\", \"N/A\")}\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-y4fBpQSNYlV"
      },
      "source": [
        "### Retrieve properties of the collection\n",
        "\n",
        "The code below will make a request to the API requesting the properties for the specific collection we want to download from. The code below prints out a few important properties"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbUSLw4MNzCU"
      },
      "source": [
        "\n",
        "# paste the id of the collection you are interested in here:\n",
        "COLLECTION_ID = 'ref_african_crops_uganda_01'\n",
        "\n",
        "# use these optional parameters to control what items are returned. maximum limit is 10000\n",
        "\n",
        "limit = 100\n",
        "bounding_box = []\n",
        "date_time = []\n",
        "\n",
        "r = requests.get(f'{API_BASE}/collections/{COLLECTION_ID}', params = {'limit':limit, 'bbox':bounding_box, 'datetime':date_time}, headers = headers)\n",
        "collection = r.json()\n",
        "\n",
        "print(f'Description: {collection[\"description\"]}')\n",
        "\n",
        "print(f'License: {collection[\"license\"]}')\n",
        "\n",
        "print(f'Citation: {collection[\"sci:citation\"]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEZMjXNsOJ8F"
      },
      "source": [
        "### Selecting an Item to Download\n",
        "\n",
        "Let's select just one item."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUhRDxvROQYB"
      },
      "source": [
        "collection = r.json()\n",
        "selected_item = None\n",
        "assets = None\n",
        "for feature in collection.get('features', []):\n",
        "    selected_item = feature\n",
        "    assets = list(feature.get('assets').keys())\n",
        "    # For demo purposes we only want the first item\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fPhs61qOwnE"
      },
      "source": [
        "#3. Downloading Assets\n",
        "\n",
        "We'll need to set up some functions to download items."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aF179T_IpBK"
      },
      "source": [
        "# First, we need to install the arrow package which will be required by some \n",
        "# functions in the code below. Other packages have already been installed.\n",
        "!pip install arrow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZ5rVujUlrZv"
      },
      "source": [
        "!pip install boto3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KffudlWdRJKY"
      },
      "source": [
        "# **Note: Kindly restart your runtime to initiate the newly installed libraries.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgiCBXQXO3Hw"
      },
      "source": [
        "import boto3 # Required to download assets hosted on S3\n",
        "import os\n",
        "from urllib.parse import urlparse\n",
        "import arrow\n",
        "from multiprocessing.pool import ThreadPool\n",
        "from tqdm import tqdm\n",
        "\n",
        "s3 = boto3.client('s3')\n",
        "\n",
        "def download_s3(uri, path):\n",
        "    parsed = urlparse(uri)\n",
        "    bucket = parsed.netloc\n",
        "    key = parsed.path[1:]\n",
        "    s3.download_file(bucket, key, os.path.join(path, key.split('/')[-1]))\n",
        "    \n",
        "def download_http(uri, path):\n",
        "    parsed = urlparse(uri)\n",
        "    r = requests.get(uri)\n",
        "    f = open(os.path.join(path, parsed.path.split('/')[-1]), 'wb')\n",
        "    for chunk in r.iter_content(chunk_size=512 * 1024): \n",
        "        if chunk:\n",
        "            f.write(chunk)\n",
        "    f.close()\n",
        "\n",
        "def get_download_uri(uri):\n",
        "    r = requests.get(uri, allow_redirects=False)\n",
        "    return r.headers['Location']\n",
        "\n",
        "def download(d):\n",
        "    href = d[0]\n",
        "    path = d[1]\n",
        "    download_uri = get_download_uri(href)\n",
        "    parsed = urlparse(download_uri)\n",
        "    \n",
        "    if parsed.scheme in ['s3']:\n",
        "        download_s3(download_uri, path)\n",
        "    elif parsed.scheme in ['http', 'https']:\n",
        "        download_http(download_uri, path)\n",
        "        \n",
        "def get_source_item_assets(args):\n",
        "    path = args[0]\n",
        "    href = args[1]\n",
        "    asset_downloads = []\n",
        "    try:\n",
        "        r = requests.get(href, headers=headers)\n",
        "    except:\n",
        "        print('ERROR: Could Not Load', href)\n",
        "        return []\n",
        "    dt = arrow.get(r.json()['properties']['datetime']).format('YYYY_MM_DD')\n",
        "    asset_path = os.path.join(path, dt)\n",
        "    if not os.path.exists(asset_path):\n",
        "        os.makedirs(asset_path)\n",
        "\n",
        "    for key, asset in r.json()['assets'].items():\n",
        "        asset_downloads.append((asset['href'], asset_path))\n",
        "        \n",
        "    return asset_downloads\n",
        "\n",
        "def download_source_and_labels(item):\n",
        "    labels = item.get('assets').get('labels')\n",
        "    links = item.get('links')\n",
        "    \n",
        "    # Make the directory to download the files to\n",
        "    path = f'uganda-crop-data/{item[\"id\"]}/'\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "    \n",
        "    source_items = []\n",
        "    \n",
        "    # Download the source imagery\n",
        "    for link in links:\n",
        "        if link['rel'] != 'source':\n",
        "            continue\n",
        "        source_items.append((path, link['href']))\n",
        "        \n",
        "    results = p.map(get_source_item_assets, source_items)\n",
        "    results.append([(labels['href'], path)])\n",
        "            \n",
        "    return results\n",
        "\n",
        "def get_items(uri, classes=None, max_items_downloaded=None, items_downloaded=0, downloads=[]):\n",
        "    print('Loading', uri, '...')\n",
        "    r = requests.get(uri, headers=headers)\n",
        "    collection = r.json()\n",
        "    for feature in collection.get('features', []):\n",
        "        # Check if the item has one of the label classes we're interested in\n",
        "        matches_class = True\n",
        "        if classes is not None:\n",
        "            matches_class = False\n",
        "            for label_class in feature['properties'].get('labels', []):\n",
        "                if label_class in classes:\n",
        "                    matches_class = True\n",
        "                    break\n",
        "            \n",
        "        # If the item does not match all of the criteria we specify, skip it\n",
        "        if not matches_class:\n",
        "            continue\n",
        "        \n",
        "        print('Getting Source Imagery Assets for', feature['id'])\n",
        "        # Download the label and source imagery for the item\n",
        "        downloads.extend(download_source_and_labels(feature))\n",
        "        \n",
        "        # Stop downloaded items if we reached the maximum we specify\n",
        "        items_downloaded += 1\n",
        "        if max_items_downloaded is not None and items_downloaded >= max_items_downloaded:\n",
        "            return downloads\n",
        "        \n",
        "    # Get the next page if results, if available\n",
        "    for link in collection.get('links', []):\n",
        "        if link['rel'] == 'next' and link['href'] is not None:\n",
        "            get_items(link['href'], classes=classes, max_items_downloaded=max_items_downloaded, items_downloaded=items_downloaded, downloads=downloads)\n",
        "    \n",
        "    return downloads"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N99ONZkhO_rS"
      },
      "source": [
        "# 4. Download labels and source imagery \n",
        "\n",
        "The function below will navigate the API and collect all the download links for labels and source imagery assets. In this function, we specified the \"max_items_downloaded\" argument which limits the number of label items downloaded. By removing this argument, you can download all of the label items which match the criteria you specify."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pcLTvZvO-5m"
      },
      "source": [
        "p = ThreadPool(20)\n",
        "to_download = get_items(f'{API_BASE}/collections/{COLLECTION_ID}/items?limit=100',\n",
        "                        max_items_downloaded=1, downloads=[])\n",
        "for d in tqdm(to_download):\n",
        "    p.map(download, d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4OEKl49RFiz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}