{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GIZ_Video_Two,_Assessment_Two.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfPKOey7P8ob"
      },
      "source": [
        "# How to access open Earth observation training data\n",
        "### **Assessment Two**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "533Q-XzAd-5Q"
      },
      "source": [
        "## Example application of learning a crop type classification model using training data from Radiant ML Hub\n",
        "---\n",
        "This Python notebook takes you through an application of learning  a classification model for classifying crop types against field IDs in a satellite image. \n",
        "\n",
        "---\n",
        "The notebook is based on a starter notebook provided for the 2020 ICLR workshop challenge at Zindi on using earth observation data for classifying crop types during the growing season: https://zindi.africa/competitions/iclr-workshop-challenge-2-radiant-earth-computer-vision-for-crop-recognition\n",
        "\n",
        "---\n",
        "This is a high level overview of the notebook:\n",
        "\n",
        "- Download data (tif files and label and field information) from Radiant ML Hub\n",
        "- Do data preprocessing by sampling the satellite images to get the data into an easy tabular form \n",
        "- Learn a classification model on this data, and experiment with grouping by field or doing pixel-wise classifications.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbhvBep2vNGQ"
      },
      "source": [
        "## **Download Data from Radiant ML Hub**\n",
        "\n",
        "At the end of this section you should have downloaded all images and labels of the crop type dataset that constitutes satellite imagery over western Kenya labeled with field IDs and respective crop types.\n",
        "\n",
        "The code in this section is essentially a clone from a starter notebook provided by Radiant Earth for downloading satellite images labeled with field IDs and crop types: https://github.com/radiantearth/mlhub-tutorials/tree/master/notebooks/2020%20CV4A%20Crop%20Type%20Challenge\n",
        "\n",
        "In this section we will:\n",
        "\n",
        "- import libraries that we use to access and get information from the Radiant ML Hub API\n",
        "- specify authentication details and API properties that we shall use whenever we access the API\n",
        "- specify the download location where the dataset will be downloaded\n",
        "- define functions to use for donwloading labels and images\n",
        "- specify collection IDs and download the respective labels and images.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYxpNNSG9SNb"
      },
      "source": [
        "### **Import required libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9wh_ALRlju7"
      },
      "source": [
        "# Required libraries\n",
        "import requests\n",
        "from urllib.parse import urlparse\n",
        "from pathlib import Path\n",
        "from datetime import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAJdOBT4xP3t"
      },
      "source": [
        "### **Authentication**\n",
        "\n",
        "Access to the Radiant MLHub API requires an access token. To get your access token, go to dashboard.mlhub.earth. If you have not used Radiant MLHub before, you will need to sign up and create a new account. Otherwise, sign in. Under Usage, you'll see your access token, which you will need. Do not share your access token with others: your usage may be limited and sharing your access token is a security risk.\n",
        "\n",
        "You can copy and paste your access token in the value for the ACCESS_TOKEN variable in this next cell. Then headers block will be used in all our requests to Radiant ML Hub's API.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_Sp500flc2k"
      },
      "source": [
        "ACCESS_TOKEN = 'PASTE THE TOKEN FROM YOUR RADIANT MLHUB DASHBOARD HERE'\n",
        "headers = {\n",
        "    'Authorization': f'Bearer {ACCESS_TOKEN}',\n",
        "    'Accept':'application/json'\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkn3twT-yenR"
      },
      "source": [
        "#### **Specify the output path to the folder where the data will be downloaded**\n",
        "\n",
        "You can first get the dataset to Google colab and use it there, or copy it to your data folder in Google drive, or download it to your data folder on your local machine.\n",
        "\n",
        "In this case, we mount Google Drive and specify the path to the data folder where the images and labels will be downloaded."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZncmyaWllPC"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWOdAnchlnfR"
      },
      "source": [
        "output_path = Path(\"/content/drive/My Drive/Colab Notebooks/data/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htFz_j5wzbdd"
      },
      "source": [
        "### **Function definitions for downloading the labels and source imagery**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yi9W6q7flqJh"
      },
      "source": [
        "def get_download_url(item, asset_key, headers):\n",
        "    asset = item.get('assets', {}).get(asset_key, None)\n",
        "    if asset is None:\n",
        "        print(f'Asset \"{asset_key}\" does not exist in this item')\n",
        "        return None\n",
        "    r = requests.get(asset.get('href'), headers=headers, allow_redirects=False)\n",
        "    return r.headers.get('Location')\n",
        "\n",
        "def download_label(url, output_path, tileid):\n",
        "    filename = urlparse(url).path.split('/')[-1]\n",
        "    outpath = output_path/tileid\n",
        "    outpath.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    r = requests.get(url)\n",
        "    f = open(outpath/filename, 'wb')\n",
        "    for chunk in r.iter_content(chunk_size=512 * 1024): \n",
        "        if chunk:\n",
        "            f.write(chunk)\n",
        "    f.close()\n",
        "    print(f'Downloaded {filename}')\n",
        "    return \n",
        "\n",
        "def download_imagery(url, output_path, tileid, date):\n",
        "    filename = urlparse(url).path.split('/')[-1]\n",
        "    outpath = output_path/tileid/date\n",
        "    outpath.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    r = requests.get(url)\n",
        "    f = open(outpath/filename, 'wb')\n",
        "    for chunk in r.iter_content(chunk_size=512 * 1024): \n",
        "        if chunk:\n",
        "            f.write(chunk)\n",
        "    f.close()\n",
        "    print(f'Downloaded {filename}')\n",
        "    return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBN1S6MT2w9P"
      },
      "source": [
        "### **Retrieving the data**\n",
        "\n",
        "Datasets are stored as collections on Radiant MLHub catalog. A collection represents the top-most data level. Typically this means the data comes from the same source for the same geography. It might include different years or sub-geographies.\n",
        "\n",
        "The two collections we shall use in the machine learning application are:\n",
        "\n",
        "- ref_african_crops_kenya_02_source: includes the multi-temporal bands of Sentinel-2\n",
        "- ref_african_crops_kenya_02_labels: includes the labels and field IDs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLlCwuCg4gAr"
      },
      "source": [
        "#### **Download labels**\n",
        "\n",
        "The assets property of the items in a collection contains all the assets associated with that item and links to download them. The labels for the item will always be the asset with the key labels. The following code will go through every item in the collection and download the labels and field_ids raster feature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZazXJwf24ztf"
      },
      "source": [
        "# paste the id of the labels collection:\n",
        "collectionId = 'ref_african_crops_kenya_02_labels'\n",
        "\n",
        "# these optional parameters can be used to control what items are returned. \n",
        "# Here, we want to download all the items so:\n",
        "limit = 100\n",
        "bounding_box = []\n",
        "date_time = []\n",
        "\n",
        "# retrieves the items and their metadata in the collection\n",
        "r = requests.get(f'https://api.radiant.earth/mlhub/v1/collections/{collectionId}/items', params={'limit':limit, 'bbox':bounding_box,'datetime':date_time}, headers=headers)\n",
        "collection = r.json()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPH_5BwGlw8i"
      },
      "source": [
        "# retrieve list of features (in this case tiles) in the collection\n",
        "for feature in collection.get('features', []):\n",
        "    assets = feature.get('assets').keys()\n",
        "    print(\"Feature\", feature.get('id'), 'with the following assets', list(assets))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvS0uEkXlzHm"
      },
      "source": [
        "for feature in collection.get('features', []):\n",
        "    \n",
        "    tileid = feature.get('id').split('tile_')[-1][:2]\n",
        "\n",
        "    # download labels\n",
        "    download_url = get_download_url(feature, 'labels', headers)\n",
        "    download_label(download_url, output_path, tileid)\n",
        "    \n",
        "    #download field_ids\n",
        "    download_url = get_download_url(feature, 'field_ids', headers)\n",
        "    download_label(download_url, output_path, tileid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXAPyVsx5XGe"
      },
      "source": [
        "#### **Download images**\n",
        "\n",
        "The imagery items associated with the tiles are linked within the links array of the tile metadata. Links which have a rel type of \"source\" are links to imagery items. By requesting the metadata for the imagery item you can retrieve download URLs for each band of the imagery."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNYxkjUGl1_n"
      },
      "source": [
        "# paste the id of the imagery collection:\n",
        "collectionId = 'ref_african_crops_kenya_02_source'\n",
        "\n",
        "# these optional parameters can be used to control what items are returned. \n",
        "# Here, we want to download all the items so:\n",
        "limit = 100\n",
        "bounding_box = []\n",
        "date_time = []\n",
        "\n",
        "# retrieves the items and their metadata in the collection\n",
        "r = requests.get(f'https://api.radiant.earth/mlhub/v1/collections/{collectionId}/items', params={'limit':limit, 'bbox':bounding_box,'datetime':date_time}, headers=headers)\n",
        "collection = r.json()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLX99JrEl7Fn"
      },
      "source": [
        "# List assets of the items\n",
        "for feature in collection.get('features', []):\n",
        "    assets = feature.get('assets').keys()\n",
        "    print(list(assets))\n",
        "    break #all the features have the same type of assets. for simplicity we break the loop here."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9Xotqj-l9Zw"
      },
      "source": [
        "# This cell downloads all the multi-spectral images throughout the growing season for this competition.\n",
        "# The size of data is about 1.5 GB, and download time depends on your internet connection. \n",
        "# Note that you only need to run this cell and download the data once.\n",
        "i = 0\n",
        "for feature in collection.get('features', []):\n",
        "    assets = feature.get('assets').keys()\n",
        "    tileid = feature.get('id').split('tile_')[-1][:2]\n",
        "    date = datetime.strftime(datetime.strptime(feature.get('properties')['datetime'], \"%Y-%m-%dT%H:%M:%SZ\"), \"%Y%m%d\")\n",
        "    for asset in assets:\n",
        "        i += 1\n",
        "        if i > 0: # if resuming after it failed\n",
        "          download_url = get_download_url(feature, asset, headers)\n",
        "          download_imagery(download_url, output_path, tileid, date)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkjfCqsvvjSZ"
      },
      "source": [
        "# **Viewing the images**\n",
        "\n",
        "In this section, we will explore the downloaded data set by viewing a single image corresponding one spectral band, then we will view an RGB image from a combination of images corresponding to the RGB colors. \n",
        "\n",
        "Again, this section of the notebook contains code from the starter notebooks on loading and visualizing a sample of .tif images from Radiant ML Hub. \n",
        "\n",
        "In the code, we use the tifffile package to read .tif images. We use the matplotlib library to view the images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MLym8hle6sv"
      },
      "source": [
        "# Install the tifffile package which we shall use to read the .tif images\n",
        "!pip install tifffile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sM2UblMsl_YH"
      },
      "source": [
        "# Import required libraries for opening and viewing\n",
        "import tifffile as tiff\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9WFyk7hyiBS"
      },
      "source": [
        "# This is a function that we shall use whenever we want to open a .tif image\n",
        "def load_file(fp):\n",
        "    \"\"\"Takes a PosixPath object or string filepath\n",
        "    and returns np array\"\"\"\n",
        "    \n",
        "    return tiff.imread(fp.__str__())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dh1HBSt_H8iW"
      },
      "source": [
        "#### **Load and view a single .tif image**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vvcl26Lkypk7"
      },
      "source": [
        "# Sample file to load:\n",
        "file_name = \"/content/drive/My Drive/Colab Notebooks/data/00/20191103/0_B01_20191103.tif\"\n",
        "band_data = load_file(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXtAfgb0yrbn"
      },
      "source": [
        "# View the sample file\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "plt.imshow(band_data, vmin=0, vmax=0.15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaiwQBtFJSa8"
      },
      "source": [
        "#### **View an RGB image**\n",
        "\n",
        "In this section, we combine a sample of the Red Green and Blue band images to view an RGB image.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWL_a94Oyuxk"
      },
      "source": [
        "# Quick way to see an RGB image. Can mess with the scaling factor to change brightness (9 in this example)\n",
        "\n",
        "import numpy as np\n",
        "def load_rgb(tile, date):\n",
        "\n",
        "  r = load_file(f\"/content/drive/My Drive/Colab Notebooks/data/{tile}/{date}/{tile[1]}_B04_{date}.tif\")\n",
        "  g = load_file(f\"/content/drive/My Drive/Colab Notebooks/data/{tile}/{date}/{tile[1]}_B03_{date}.tif\")\n",
        "  b = load_file(f\"/content/drive/My Drive/Colab Notebooks/data/{tile}/{date}/{tile[1]}_B02_{date}.tif\")\n",
        "  arr = np.dstack((r, g, b))\n",
        "  print(max(g.flatten()))\n",
        "  return arr\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 18))\n",
        "ax.imshow(load_rgb('00', '20191103')*9)\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFtk8wvz53JV"
      },
      "source": [
        "# **Data Pre-processing for machine learning**\n",
        "\n",
        "Now that you have downloaded and explored the dataset by viewing a sample of images, let's now transform the downloaded data for training and evaluating classificatnon models. \n",
        "\n",
        "First of all, we need to get all the dates constituting the observations in the dataset and the bands in each observation into lists that we shall use later to specify images or go through all images.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHlhcvxSykOm"
      },
      "source": [
        "# List of dates that an observation from Sentinel-2 is provided in the training dataset\n",
        "\n",
        "dates = [datetime.datetime(2019, 6, 6, 8, 10, 7),\n",
        "         datetime.datetime(2019, 7, 1, 8, 10, 4),\n",
        "         datetime.datetime(2019, 7, 6, 8, 10, 8),\n",
        "         datetime.datetime(2019, 7, 11, 8, 10, 4),\n",
        "         datetime.datetime(2019, 7, 21, 8, 10, 4),\n",
        "         datetime.datetime(2019, 8, 5, 8, 10, 7),\n",
        "         datetime.datetime(2019, 8, 15, 8, 10, 6),\n",
        "         datetime.datetime(2019, 8, 25, 8, 10, 4),\n",
        "         datetime.datetime(2019, 9, 9, 8, 9, 58),\n",
        "         datetime.datetime(2019, 9, 19, 8, 9, 59),\n",
        "         datetime.datetime(2019, 9, 24, 8, 9, 59),\n",
        "         datetime.datetime(2019, 10, 4, 8, 10),\n",
        "         datetime.datetime(2019, 11, 3, 8, 10)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIGv9eWWynrh"
      },
      "source": [
        "# List of bands in each observation\n",
        "\n",
        "bands = ['B01', 'B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B8A', 'B09', 'B11', 'B12', 'CLD']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eRqRopTF2xF"
      },
      "source": [
        "### **Getting data for each pixel in fields**\n",
        "\n",
        "This is where we start massaging the data into a format we can use. \n",
        "\n",
        "We start by reading in the labels, finding the pixel locations of all the fields (most are only a few pixels in size) and storing the pixel locations, the field ID and the label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2COu6wT53XR"
      },
      "source": [
        "# Not super efficient but  ¯\\_(ツ)_/¯\n",
        "import pandas as pd\n",
        "\n",
        "row_locs = []\n",
        "col_locs = []\n",
        "field_ids = []\n",
        "labels = []\n",
        "tiles = []\n",
        "for tile in range(4):\n",
        "  fids = f'/content/drive/My Drive/Colab Notebooks/data/0{tile}/{tile}_field_id.tif'\n",
        "  labs = f'/content/drive/My Drive/Colab Notebooks/data/0{tile}/{tile}_label.tif'\n",
        "  fid_arr = load_file(fids)\n",
        "  lab_arr = load_file(labs)\n",
        "  for row in range(len(fid_arr)):\n",
        "    for col in range(len(fid_arr[0])):\n",
        "      if fid_arr[row][col] != 0:\n",
        "        row_locs.append(row)\n",
        "        col_locs.append(col)\n",
        "        field_ids.append(fid_arr[row][col])\n",
        "        labels.append(lab_arr[row][col])\n",
        "        tiles.append(tile)\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'fid':field_ids,\n",
        "    'label':labels,\n",
        "    'row_loc': row_locs,\n",
        "    'col_loc':col_locs,\n",
        "    'tile':tiles\n",
        "})\n",
        "\n",
        "print(df.shape)\n",
        "print(df.groupby('fid').count().shape)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EY6ktMlA1t-H"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHTRLzG9zymk"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "Then we loop through all the images, sampling the different image bands to get the values for each pixel in each field.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YKFWmC87nBC"
      },
      "source": [
        "# Sample the bands at different dates as columns in our new dataframe\n",
        "col_names = []\n",
        "col_values = []\n",
        "\n",
        "for tile in range(4): # 1) For each tile\n",
        "  print('Tile: ', tile)\n",
        "  for d in dates: # 2) For each date\n",
        "    print(str(d))\n",
        "    d = ''.join(str(d.date()).split('-')) # Nice date string\n",
        "    t = '0'+str(tile)\n",
        "    for b in bands: # 3) For each band\n",
        "      col_name = d+'_'+b\n",
        "      \n",
        "      if tile == 0:\n",
        "        # If the column doesn't exist, create it and populate with 0s\n",
        "        df[col_name] = 0\n",
        "\n",
        "      # Load im\n",
        "      im = load_file(f\"/content/drive/My Drive/Colab Notebooks/data/{t}/{d}/{t[1]}_{b}_{d}.tif\")\n",
        "      \n",
        "      # Going four levels deep. Each second on the outside is four weeks in this loop\n",
        "      # If we die here, there's no waking up.....\n",
        "      vals = []\n",
        "      for row, col in df.loc[df.tile == tile][['row_loc', 'col_loc']].values: # 4) For each location of a pixel in a field\n",
        "        vals.append(im[row][col])\n",
        "      df.loc[df.tile == tile, col_name] = vals\n",
        "df.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRQGkI-o_om4"
      },
      "source": [
        "df.to_csv('sampled_data.csv', index=False)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WJua4n10xpO"
      },
      "source": [
        "---\n",
        "\n",
        "We can copy the prepared data (sampled_data.csv) to the data folder in Google Drive\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NODO7QTBQ0A"
      },
      "source": [
        "!cp 'sampled_data.csv' '/content/drive/My Drive/Colab Notebooks/data/sampled_data.csv' # You can mount drive and save like this, or just download sampled_data.csv and use that later."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zf7NsiS6IjsI"
      },
      "source": [
        "# **Using the prepared data for machine learning crop type classification models**\n",
        "\n",
        "---\n",
        "\n",
        "Now that we have our data in a nice tabular data format, we can try some simple machine learning methods using the sklearn package.\n",
        "\n",
        "We can restart the runtime here and load in the data we saved earlier.\n",
        "\n",
        "---\n",
        "\n",
        "### **Import classifiers from sklearn**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzMHrTnVjvfz"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier # Random Forest classifier, AdaBoost classifier\n",
        "from sklearn.neighbors import KNeighborsClassifier # K nearest neighbor classifier\n",
        "from sklearn.tree import DecisionTreeClassifier # Decision tree classifier\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier # Gaussian process classifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.metrics import log_loss # evaluation metric"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8x4dVsikOr3"
      },
      "source": [
        "### **Load data set**\n",
        "\n",
        "We load the data set and split it into a training set (for training a classifier) and a test set (for evaluating the classifier).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AR33yXiFkKUN"
      },
      "source": [
        "# Load the data\n",
        "df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/data/sampled_data.csv')\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFcYYXroI8EA"
      },
      "source": [
        "# Split into train and test sets\n",
        "train = df.loc[df.label != 0]\n",
        "test =  df.loc[df.label == 0]\n",
        "train.shape, test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28sCD8BflBCg"
      },
      "source": [
        "# Split train into train and validation (val) set, so that we can score our models locally.\n",
        "\n",
        "# We split on field ID since we want to predict for unseen FIELDS\n",
        "val_field_ids = train.groupby('fid').mean().reset_index()['fid'].sample(frac=0.3).values\n",
        "tr = train.loc[~train.fid.isin(val_field_ids)].copy()\n",
        "val = train.loc[train.fid.isin(val_field_ids)].copy()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tkqOukI3ROq"
      },
      "source": [
        "### **Classification model training**\n",
        "\n",
        "We can train a classifier to predict on pixels and then combine, or we can train a classfier by first grouping into fields. Let's do both and compare!\n",
        "\n",
        "**A. Training and predicting on pixels**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fezDgkp7Olx"
      },
      "source": [
        "# Split into X and Y for modelling\n",
        "X_train, y_train = tr[tr.columns[5:]], tr['label']\n",
        "X_val, y_val = val[val.columns[5:]], val['label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9N26RIBP3gRj"
      },
      "source": [
        "# Train a classification model (takes a few minutes since we have plenty of rows)\n",
        "model = RandomForestClassifier(n_estimators=500)\n",
        "model.fit(X_train.fillna(0), y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fA_qja5Pkmjp"
      },
      "source": [
        "# Predict on pixels\n",
        "\n",
        "# We use the predict_proba() function to get predicted probabilities\n",
        "preds = model.predict_proba(X_val.fillna(0))\n",
        "\n",
        "# Add to val dataframe as columns\n",
        "for i in range(7):\n",
        "  val[str(i+1)] = preds[:,i]\n",
        "\n",
        "# Get 'true' vals as columns in val\n",
        "for c in range(1, 8):\n",
        "  val['true'+str(c)] = (val['label'] == c).astype(int)\n",
        "\n",
        "pred_cols = [str(i) for i in range(1, 8)]\n",
        "true_cols = ['true'+str(i) for i in range(1, 8)]\n",
        "\n",
        "# Calculate the evaluation score - using the log-loss metric\n",
        "#print('Pixel score:', log_loss(val[true_cols], val[pred_cols]))\n",
        "print('Field score:', log_loss(val.groupby('fid').mean()[true_cols], val.groupby('fid').mean()[pred_cols])) # This is what we'll use to compare\n",
        "\n",
        "# Inspect or compare visually\n",
        "val[['label']+true_cols+pred_cols].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HaP1oeC6Vu5"
      },
      "source": [
        "**B. Training and predicting on fields**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzjwQTEHoCeY"
      },
      "source": [
        "# Group training data into fields\n",
        "\n",
        "train_grouped = tr.groupby('fid').mean().reset_index()\n",
        "val_grouped = val.groupby('fid').mean().reset_index()\n",
        "X_train, y_train = train_grouped[train_grouped.columns[5:]], train_grouped['label']\n",
        "X_val, y_val = val_grouped[train_grouped.columns[5:]], val_grouped['label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXMsh1S3ZlrM"
      },
      "source": [
        "# Train a classification model\n",
        "model = RandomForestClassifier(n_estimators=500)\n",
        "model.fit(X_train.fillna(0), y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOVebGtQZrEM"
      },
      "source": [
        "# Get predicted probabilities\n",
        "preds = model.predict_proba(X_val.fillna(0))\n",
        "\n",
        "# Add to val_grouped dataframe as columns\n",
        "for i in range(7):\n",
        "  val_grouped[str(i+1)] = preds[:,i]\n",
        "\n",
        "# Get 'true' vals as columns in val\n",
        "for c in range(1, 8):\n",
        "  val_grouped['true'+str(c)] = (val_grouped['label'] == c).astype(int)\n",
        "\n",
        "pred_cols = [str(i) for i in range(1, 8)]\n",
        "true_cols = ['true'+str(i) for i in range(1, 8)]\n",
        "val_grouped[['label']+true_cols+pred_cols].head()\n",
        "\n",
        "# Already grouped, but just to double check:\n",
        "print('Field score:', log_loss(val_grouped.groupby('fid').mean()[true_cols], val_grouped.groupby('fid').mean()[pred_cols]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlg_5vYRpsQT"
      },
      "source": [
        "## **PRACTICAL EXERCISE**\n",
        "\n",
        "### **If you were able to complete train and predict in A and B, answer the following questions**\n",
        "\n",
        "#### **Qn 1.** Which of the two approaches is much faster?\n",
        "\n",
        "#### **Qn 2.** Which of the two approaches is more accurate?\n",
        "\n",
        "#### **Qn 3 - Hands on.** Instead of the Random Forest classifier, apply other classifiers from the sklearn package and compare their performance using the log loss metric."
      ]
    }
  ]
}